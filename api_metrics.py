#!/usr/bin/env python3
"""
–°–∏—Å—Ç–µ–º–∞ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ API
"""

import time
import sqlite3
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import statistics
from config import logger, API_METRICS_DB_PATH, API_METRICS_RETENTION_DAYS, API_METRICS_ALERT_THRESHOLDS

class MetricType(Enum):
    """–¢–∏–ø—ã –º–µ—Ç—Ä–∏–∫"""
    RESPONSE_TIME = "response_time"
    SUCCESS_RATE = "success_rate"
    ERROR_RATE = "error_rate"
    THROUGHPUT = "throughput"
    CACHE_HIT_RATE = "cache_hit_rate"
    RETRY_COUNT = "retry_count"

@dataclass
class APIMetric:
    """–ú–µ—Ç—Ä–∏–∫–∞ API"""
    timestamp: datetime
    endpoint: str
    metric_type: MetricType
    value: float
    metadata: Dict[str, Any]

class APIMetricsCollector:
    """–°–±–æ—Ä—â–∏–∫ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ API"""
    
    def __init__(self, db_path: str = API_METRICS_DB_PATH):
        self.db_path = db_path
        self._init_db()
        
        # –ö—ç—à –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        self.metrics_cache = {}
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
        self.aggregation_intervals = [1, 5, 15, 60]  # –º–∏–Ω—É—Ç—ã
        self.retention_days = API_METRICS_RETENTION_DAYS
    
    def _init_db(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–µ—Ç—Ä–∏–∫"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å—ã—Ä—ã—Ö –º–µ—Ç—Ä–∏–∫
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS api_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                endpoint TEXT NOT NULL,
                metric_type TEXT NOT NULL,
                value REAL NOT NULL,
                metadata TEXT
            )
        ''')
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –æ—Ç–¥–µ–ª—å–Ω–æ
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_metrics_timestamp ON api_metrics(timestamp)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_metrics_endpoint ON api_metrics(endpoint)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_metrics_type ON api_metrics(metric_type)')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS api_metrics_aggregated (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                interval_minutes INTEGER NOT NULL,
                endpoint TEXT NOT NULL,
                metric_type TEXT NOT NULL,
                avg_value REAL,
                min_value REAL,
                max_value REAL,
                count INTEGER
            )
        ''')
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_agg_timestamp ON api_metrics_aggregated(timestamp)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_agg_endpoint ON api_metrics_aggregated(endpoint)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_agg_type ON api_metrics_aggregated(metric_type)')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS api_alerts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                alert_type TEXT NOT NULL,
                endpoint TEXT,
                message TEXT,
                severity TEXT,
                resolved BOOLEAN DEFAULT FALSE
            )
        ''')
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_alerts_timestamp ON api_alerts(timestamp)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_alerts_type ON api_alerts(alert_type)')
        
        conn.commit()
        conn.close()
        logger.info("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ API –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    def record_metric(self, endpoint: str, metric_type: MetricType, value: float, 
                     metadata: Dict[str, Any] = None):
        """
        –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫—É
        
        Args:
            endpoint: –≠–Ω–¥–ø–æ–∏–Ω—Ç API
            metric_type: –¢–∏–ø –º–µ—Ç—Ä–∏–∫–∏
            value: –ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            metadata: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO api_metrics (timestamp, endpoint, metric_type, value, metadata)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                datetime.now(),
                endpoint,
                metric_type.value,
                value,
                json.dumps(metadata) if metadata else None
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –º–µ—Ç—Ä–∏–∫–∏: {e}")
    
    def record_response_time(self, endpoint: str, response_time: float, 
                           status_code: int = None, error: str = None):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫—É –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞"""
        metadata = {
            'status_code': status_code,
            'error': error,
            'timestamp': datetime.now().isoformat()
        }
        
        self.record_metric(endpoint, MetricType.RESPONSE_TIME, response_time, metadata)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª–µ—Ä—Ç—ã
        if response_time > API_METRICS_ALERT_THRESHOLDS['response_time_ms']:
            self._create_alert("high_response_time", endpoint, 
                             f"–í—ã—Å–æ–∫–æ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {response_time:.0f}–º—Å")
    
    def record_success_rate(self, endpoint: str, success_count: int, total_count: int):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫—É —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏"""
        success_rate = (success_count / total_count * 100) if total_count > 0 else 0
        metadata = {
            'success_count': success_count,
            'total_count': total_count
        }
        
        self.record_metric(endpoint, MetricType.SUCCESS_RATE, success_rate, metadata)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª–µ—Ä—Ç—ã
        if success_rate < API_METRICS_ALERT_THRESHOLDS['success_rate_percent']:
            self._create_alert("low_success_rate", endpoint, 
                             f"–ù–∏–∑–∫–∞—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å: {success_rate:.1f}%")
    
    def record_error_rate(self, endpoint: str, error_count: int, total_count: int):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫—É –æ—à–∏–±–æ–∫"""
        error_rate = (error_count / total_count * 100) if total_count > 0 else 0
        metadata = {
            'error_count': error_count,
            'total_count': total_count
        }
        
        self.record_metric(endpoint, MetricType.ERROR_RATE, error_rate, metadata)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª–µ—Ä—Ç—ã
        if error_rate > API_METRICS_ALERT_THRESHOLDS['error_rate_percent']:
            self._create_alert("high_error_rate", endpoint, 
                             f"–í—ã—Å–æ–∫–∞—è —á–∞—Å—Ç–æ—Ç–∞ –æ—à–∏–±–æ–∫: {error_rate:.1f}%")
    
    def record_throughput(self, endpoint: str, requests_per_minute: float):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫—É –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏"""
        metadata = {
            'requests_per_minute': requests_per_minute
        }
        
        self.record_metric(endpoint, MetricType.THROUGHPUT, requests_per_minute, metadata)
    
    def record_cache_hit_rate(self, endpoint: str, hit_rate: float):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫—É –∫—ç—à–∞"""
        metadata = {
            'hit_rate': hit_rate
        }
        
        self.record_metric(endpoint, MetricType.CACHE_HIT_RATE, hit_rate, metadata)
    
    def record_retry_count(self, endpoint: str, retry_count: int):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫—É –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫"""
        metadata = {
            'retry_count': retry_count
        }
        
        self.record_metric(endpoint, MetricType.RETRY_COUNT, retry_count, metadata)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª–µ—Ä—Ç—ã
        if retry_count > 3:
            self._create_alert("high_retry_count", endpoint, 
                             f"–ú–Ω–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫: {retry_count}")
    
    def _create_alert(self, alert_type: str, endpoint: str, message: str):
        """–°–æ–∑–¥–∞–µ—Ç –∞–ª–µ—Ä—Ç"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO api_alerts (timestamp, alert_type, endpoint, message, severity)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                datetime.now(),
                alert_type,
                endpoint,
                message,
                'high' if alert_type in ['high_error_rate', 'high_response_time'] else 'medium'
            ))
            
            conn.commit()
            conn.close()
            
            logger.warning(f"–ê–ª–µ—Ä—Ç —Å–æ–∑–¥–∞–Ω: {alert_type} - {message}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∞–ª–µ—Ä—Ç–∞: {e}")
    
    def get_metrics_summary(self, hours: int = 24) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å–≤–æ–¥–∫—É –º–µ—Ç—Ä–∏–∫ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —á–∞—Å–æ–≤
        
        Args:
            hours: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å–≤–æ–¥–∫–æ–π –º–µ—Ç—Ä–∏–∫
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            start_time = datetime.now() - timedelta(hours=hours)
            
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞–º
            cursor.execute('''
                SELECT 
                    endpoint,
                    metric_type,
                    AVG(value) as avg_value,
                    MIN(value) as min_value,
                    MAX(value) as max_value,
                    COUNT(*) as count
                FROM api_metrics 
                WHERE timestamp >= ?
                GROUP BY endpoint, metric_type
            ''', (start_time,))
            
            metrics_summary = {}
            for row in cursor.fetchall():
                endpoint, metric_type, avg_value, min_value, max_value, count = row
                
                if endpoint not in metrics_summary:
                    metrics_summary[endpoint] = {}
                
                metrics_summary[endpoint][metric_type] = {
                    'avg': avg_value or 0,
                    'min': min_value or 0,
                    'max': max_value or 0,
                    'count': count
                }
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤
            cursor.execute('''
                SELECT 
                    alert_type,
                    COUNT(*) as count,
                    COUNT(CASE WHEN resolved = FALSE THEN 1 END) as unresolved
                FROM api_alerts 
                WHERE timestamp >= ?
                GROUP BY alert_type
            ''', (start_time,))
            
            alerts_summary = {}
            for row in cursor.fetchall():
                alert_type, count, unresolved = row
                alerts_summary[alert_type] = {
                    'total': count,
                    'unresolved': unresolved
                }
            
            conn.close()
            
            return {
                'period_hours': hours,
                'metrics': metrics_summary,
                'alerts': alerts_summary
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–≤–æ–¥–∫–∏ –º–µ—Ç—Ä–∏–∫: {e}")
            return {}
    
    def get_performance_trends(self, hours: int = 24) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Ç—Ä–µ–Ω–¥—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        
        Args:
            hours: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ç—Ä–µ–Ω–¥–∞–º–∏
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            start_time = datetime.now() - timedelta(hours=hours)
            
            # –¢—Ä–µ–Ω–¥—ã –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞ –ø–æ —á–∞—Å–∞–º
            cursor.execute('''
                SELECT 
                    strftime('%H', timestamp) as hour,
                    endpoint,
                    AVG(value) as avg_response_time
                FROM api_metrics 
                WHERE timestamp >= ? AND metric_type = 'response_time'
                GROUP BY hour, endpoint
                ORDER BY hour
            ''', (start_time,))
            
            response_time_trends = {}
            for row in cursor.fetchall():
                hour, endpoint, avg_response_time = row
                if endpoint not in response_time_trends:
                    response_time_trends[endpoint] = {}
                response_time_trends[endpoint][hour] = avg_response_time or 0
            
            # –¢—Ä–µ–Ω–¥—ã —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
            cursor.execute('''
                SELECT 
                    strftime('%H', timestamp) as hour,
                    endpoint,
                    AVG(value) as avg_success_rate
                FROM api_metrics 
                WHERE timestamp >= ? AND metric_type = 'success_rate'
                GROUP BY hour, endpoint
                ORDER BY hour
            ''', (start_time,))
            
            success_rate_trends = {}
            for row in cursor.fetchall():
                hour, endpoint, avg_success_rate = row
                if endpoint not in success_rate_trends:
                    success_rate_trends[endpoint] = {}
                success_rate_trends[endpoint][hour] = avg_success_rate or 0
            
            conn.close()
            
            return {
                'response_time_trends': response_time_trends,
                'success_rate_trends': success_rate_trends
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ç—Ä–µ–Ω–¥–æ–≤: {e}")
            return {}
    
    def generate_performance_report(self, hours: int = 24) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        
        Args:
            hours: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
        """
        summary = self.get_metrics_summary(hours)
        trends = self.get_performance_trends(hours)
        
        if not summary:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
        
        report = f"üìä *–û—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ API –∑–∞ {hours}—á*\n\n"
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞–º
        for endpoint, metrics in summary.get('metrics', {}).items():
            report += f"üîó *{endpoint}:*\n"
            
            if 'response_time' in metrics:
                rt = metrics['response_time']
                report += f"  ‚è±Ô∏è –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {rt['avg']:.0f}–º—Å (–º–∏–Ω: {rt['min']:.0f}, –º–∞–∫—Å: {rt['max']:.0f})\n"
            
            if 'success_rate' in metrics:
                sr = metrics['success_rate']
                report += f"  ‚úÖ –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {sr['avg']:.1f}%\n"
            
            if 'error_rate' in metrics:
                er = metrics['error_rate']
                report += f"  ‚ùå –û—à–∏–±–∫–∏: {er['avg']:.1f}%\n"
            
            if 'throughput' in metrics:
                tp = metrics['throughput']
                report += f"  üìà –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å: {tp['avg']:.1f} –∑–∞–ø—Ä/–º–∏–Ω\n"
            
            if 'cache_hit_rate' in metrics:
                chr = metrics['cache_hit_rate']
                report += f"  üíæ –ö—ç—à: {chr['avg']:.1f}%\n"
            
            report += "\n"
        
        # –ê–ª–µ—Ä—Ç—ã
        alerts = summary.get('alerts', {})
        if alerts:
            report += "üö® *–ê–ª–µ—Ä—Ç—ã:*\n"
            for alert_type, alert_data in alerts.items():
                unresolved = alert_data['unresolved']
                total = alert_data['total']
                report += f"  {alert_type}: {unresolved}/{total} –Ω–µ—Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö\n"
        
        # –¢—Ä–µ–Ω–¥—ã
        if trends.get('response_time_trends'):
            report += "\nüìà *–¢—Ä–µ–Ω–¥—ã –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞:*\n"
            for endpoint, hours_data in trends['response_time_trends'].items():
                if hours_data:
                    avg_rt = sum(hours_data.values()) / len(hours_data)
                    report += f"  {endpoint}: {avg_rt:.0f}–º—Å (—Å—Ä–µ–¥–Ω–µ–µ)\n"
        
        return report
    
    def cleanup_old_metrics(self, days: int = 30):
        """
        –û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        
        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cutoff_date = datetime.now() - timedelta(days=days)
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            cursor.execute('DELETE FROM api_metrics WHERE timestamp < ?', (cutoff_date,))
            deleted_metrics = cursor.rowcount
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            cursor.execute('DELETE FROM api_metrics_aggregated WHERE timestamp < ?', (cutoff_date,))
            deleted_aggregated = cursor.rowcount
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∞–ª–µ—Ä—Ç—ã
            cursor.execute('DELETE FROM api_alerts WHERE timestamp < ?', (cutoff_date,))
            deleted_alerts = cursor.rowcount
            
            conn.commit()
            conn.close()
            
            logger.info(f"–û—á–∏—â–µ–Ω–æ {deleted_metrics} –º–µ—Ç—Ä–∏–∫, {deleted_aggregated} –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö, {deleted_alerts} –∞–ª–µ—Ä—Ç–æ–≤ —Å—Ç–∞—Ä—à–µ {days} –¥–Ω–µ–π")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ —Å—Ç–∞—Ä—ã—Ö –º–µ—Ç—Ä–∏–∫: {e}")

class MetricsDecorator:
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫"""
    
    def __init__(self, metrics_collector: APIMetricsCollector):
        self.metrics_collector = metrics_collector
    
    def __call__(self, func):
        def wrapper(*args, **kwargs):
            start_time = time.time()
            endpoint = func.__name__
            
            try:
                result = func(*args, **kwargs)
                response_time = (time.time() - start_time) * 1000
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫—É –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞
                self.metrics_collector.record_response_time(endpoint, response_time, 200)
                
                return result
                
            except Exception as e:
                response_time = (time.time() - start_time) * 1000
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫—É –æ—à–∏–±–∫–∏
                self.metrics_collector.record_response_time(endpoint, response_time, 500, str(e))
                
                raise
        
        return wrapper 