"""
–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç–∏ –∏ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –≤ –∑–∞–∫—É–ø–∫–∞—Ö
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple, Optional
import json
import csv
from pathlib import Path
from config import (
    DAYS_FORECAST_SHORT, DAYS_FORECAST_LONG, SALES_HISTORY_DAYS,
    DAYS_TO_ANALYZE, get_moq_for_sku, logger
)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º ML –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é
try:
    from ml_integration import MLForecastIntegration
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False
    logger.warning("ML –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")

class DataValidator:
    """–ö–ª–∞—Å—Å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    @staticmethod
    def validate_sales_data(sales_data: List[Dict[str, Any]]) -> Tuple[bool, List[str]]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (is_valid, error_messages)
        """
        errors = []
        
        if not sales_data:
            errors.append("–î–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –ø—É—Å—Ç—ã")
            return False, errors
        
        required_fields = ['sku', 'date', 'quantity']
        for i, record in enumerate(sales_data):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
            for field in required_fields:
                if field not in record:
                    errors.append(f"–ó–∞–ø–∏—Å—å {i}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ '{field}'")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
            if 'sku' in record and not isinstance(record['sku'], str):
                errors.append(f"–ó–∞–ø–∏—Å—å {i}: SKU –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π")
            
            if 'quantity' in record:
                try:
                    quantity = float(record['quantity'])
                    if quantity < 0:
                        errors.append(f"–ó–∞–ø–∏—Å—å {i}: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º")
                except (ValueError, TypeError):
                    errors.append(f"–ó–∞–ø–∏—Å—å {i}: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ")
            
            if 'date' in record:
                try:
                    pd.to_datetime(record['date'])
                except:
                    errors.append(f"–ó–∞–ø–∏—Å—å {i}: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –¥–∞—Ç–∞")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã–±—Ä–æ—Å—ã –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ
            if 'quantity' in record:
                try:
                    quantity = float(record['quantity'])
                    if quantity > 1000:  # –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
                        errors.append(f"–ó–∞–ø–∏—Å—å {i}: –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ ({quantity})")
                except:
                    pass
        
        return len(errors) == 0, errors
    
    @staticmethod
    def validate_stocks_data(stocks_data: List[Dict[str, Any]]) -> Tuple[bool, List[str]]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö
        """
        errors = []
        
        if not stocks_data:
            errors.append("–î–∞–Ω–Ω—ã–µ –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö –ø—É—Å—Ç—ã")
            return False, errors
        
        required_fields = ['sku', 'stock', 'reserved']
        for i, record in enumerate(stocks_data):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
            for field in required_fields:
                if field not in record:
                    errors.append(f"–ó–∞–ø–∏—Å—å {i}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ '{field}'")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
            if 'sku' in record and not isinstance(record['sku'], str):
                errors.append(f"–ó–∞–ø–∏—Å—å {i}: SKU –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π")
            
            for field in ['stock', 'reserved']:
                if field in record:
                    try:
                        value = float(record[field])
                        if value < 0:
                            errors.append(f"–ó–∞–ø–∏—Å—å {i}: {field} –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º")
                    except (ValueError, TypeError):
                        errors.append(f"–ó–∞–ø–∏—Å—å {i}: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ {field}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏–∫—É: –∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ –æ–±—â–µ–≥–æ –æ—Å—Ç–∞—Ç–∫–∞
            if 'stock' in record and 'reserved' in record:
                try:
                    stock = float(record['stock'])
                    reserved = float(record['reserved'])
                    if reserved > stock:
                        errors.append(f"–ó–∞–ø–∏—Å—å {i}: –∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ ({reserved}) –±–æ–ª—å—à–µ –æ–±—â–µ–≥–æ –æ—Å—Ç–∞—Ç–∫–∞ ({stock})")
                except:
                    pass
        
        return len(errors) == 0, errors
    
    @staticmethod
    def clean_sales_data(sales_df: pd.DataFrame) -> pd.DataFrame:
        """
        –û—á–∏—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –æ—Ç –≤—ã–±—Ä–æ—Å–æ–≤ –∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        """
        if sales_df.empty:
            return sales_df
        
        original_count = len(sales_df)
        
        # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞–º–∏
        sales_df = sales_df[sales_df['quantity'] >= 0]
        
        # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞—Ç–∞–º–∏
        sales_df = sales_df.dropna(subset=['date'])
        
        # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏ —Å –ø—É—Å—Ç—ã–º–∏ SKU
        sales_df = sales_df[sales_df['sku'].notna() & (sales_df['sku'] != '')]
        
        # –£–¥–∞–ª—è–µ–º –≤—ã–±—Ä–æ—Å—ã (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ > 3 —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ)
        if len(sales_df) > 10:
            q1 = sales_df['quantity'].quantile(0.25)
            q3 = sales_df['quantity'].quantile(0.75)
            iqr = q3 - q1
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr
            
            sales_df = sales_df[
                (sales_df['quantity'] >= lower_bound) & 
                (sales_df['quantity'] <= upper_bound)
            ]
        
        cleaned_count = len(sales_df)
        if original_count != cleaned_count:
            logger.warning(f"–û—á–∏—â–µ–Ω–æ {original_count - cleaned_count} –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –æ –ø—Ä–æ–¥–∞–∂–∞—Ö")
        
        return sales_df
    
    @staticmethod
    def clean_stocks_data(stocks_df: pd.DataFrame) -> pd.DataFrame:
        """
        –û—á–∏—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö
        """
        if stocks_df.empty:
            return stocks_df
        
        original_count = len(stocks_df)
        
        # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        stocks_df = stocks_df[
            (stocks_df['stock'] >= 0) & 
            (stocks_df['reserved'] >= 0)
        ]
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏: –∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ –æ–±—â–µ–≥–æ –æ—Å—Ç–∞—Ç–∫–∞
        stocks_df['reserved'] = stocks_df['reserved'].clip(upper=stocks_df['stock'])
        
        # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏ —Å –ø—É—Å—Ç—ã–º–∏ SKU
        stocks_df = stocks_df[stocks_df['sku'].notna() & (stocks_df['sku'] != '')]
        
        cleaned_count = len(stocks_df)
        if original_count != cleaned_count:
            logger.warning(f"–û—á–∏—â–µ–Ω–æ {original_count - cleaned_count} –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö")
        
        return stocks_df

class PurchaseForecast:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –∑–∞–∫—É–ø–æ–∫"""
    
    def __init__(self):
        self.days_forecast_short = DAYS_FORECAST_SHORT
        self.days_forecast_long = DAYS_FORECAST_LONG
        self.sales_history_days = SALES_HISTORY_DAYS
    
    def prepare_sales_data(self, sales_data: List[Dict[str, Any]]) -> pd.DataFrame:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
        """
        logger.info("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö...")
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        is_valid, errors = DataValidator.validate_sales_data(sales_data)
        if not is_valid:
            logger.error("–û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö:")
            for error in errors[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 –æ—à–∏–±–æ–∫
                logger.error(f"  - {error}")
            if len(errors) > 10:
                logger.error(f"  ... –∏ –µ—â–µ {len(errors) - 10} –æ—à–∏–±–æ–∫")
            return pd.DataFrame()
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
        df = pd.DataFrame(sales_data)
        
        if df.empty:
            logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö")
            return pd.DataFrame()
        
        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç –≤—ã–±—Ä–æ—Å–æ–≤ –∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        df = DataValidator.clean_sales_data(df)
        
        if df.empty:
            logger.warning("–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–µ–π")
            return pd.DataFrame()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞—Ç—ã
        df['date'] = pd.to_datetime(df['date'])
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç
        min_date = df['date'].min()
        max_date = df['date'].max()
        date_range = (max_date - min_date).days
        
        logger.info(f"–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç: {min_date.date()} - {max_date.date()} ({date_range} –¥–Ω–µ–π)")
        
        if date_range < DAYS_TO_ANALYZE:
            logger.warning(f"–ú–∞–ª–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–º–µ–Ω–µ–µ {DAYS_TO_ANALYZE} –¥–Ω–µ–π)")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ SKU –∏ –¥–∞—Ç–µ
        sales_by_sku = df.groupby(['sku', 'date']).agg({
            'quantity': 'sum',
            'revenue': 'sum'
        }).reset_index()
        
        logger.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(sales_by_sku)} –∑–∞–ø–∏—Å–µ–π –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –¥–ª—è {sales_by_sku['sku'].nunique()} SKU")
        return sales_by_sku
    
    def prepare_stocks_data(self, stocks_data: List[Dict[str, Any]]) -> pd.DataFrame:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
        """
        logger.info("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö...")
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        is_valid, errors = DataValidator.validate_stocks_data(stocks_data)
        if not is_valid:
            logger.error("–û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö:")
            for error in errors[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 –æ—à–∏–±–æ–∫
                logger.error(f"  - {error}")
            if len(errors) > 10:
                logger.error(f"  ... –∏ –µ—â–µ {len(errors) - 10} –æ—à–∏–±–æ–∫")
            return pd.DataFrame()
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
        df = pd.DataFrame(stocks_data)
        
        if df.empty:
            logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö")
            return pd.DataFrame()
        
        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        df = DataValidator.clean_stocks_data(df)
        
        if df.empty:
            logger.warning("–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–µ–π")
            return pd.DataFrame()
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ SKU
        stocks_by_sku = df.groupby('sku').agg({
            'stock': 'sum',
            'reserved': 'sum'
        }).reset_index()
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–π –æ—Å—Ç–∞—Ç–æ–∫
        stocks_by_sku['available_stock'] = stocks_by_sku['stock'] - stocks_by_sku['reserved']
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –æ—Å—Ç–∞—Ç–∫–∏
        negative_stocks = stocks_by_sku[stocks_by_sku['available_stock'] < 0]
        if not negative_stocks.empty:
            logger.warning(f"–ù–∞–π–¥–µ–Ω–æ {len(negative_stocks)} SKU —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –æ—Å—Ç–∞—Ç–∫–∞–º–∏")
            for _, row in negative_stocks.head(3).iterrows():
                logger.warning(f"  SKU {row['sku']}: stock={row['stock']}, reserved={row['reserved']}, available={row['available_stock']}")
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –æ—Å—Ç–∞—Ç–∫–∏
        stocks_by_sku['available_stock'] = stocks_by_sku['available_stock'].clip(lower=0)
        
        logger.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(stocks_by_sku)} –∑–∞–ø–∏—Å–µ–π –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö –¥–ª—è {stocks_by_sku['sku'].nunique()} SKU")
        return stocks_by_sku
    
    def calculate_daily_sales(self, sales_df: pd.DataFrame, stocks_df: pd.DataFrame = None) -> pd.DataFrame:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω—é—é –¥–Ω–µ–≤–Ω—É—é –ø—Ä–æ–¥–∞–∂—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ SKU, –∏—Å–∫–ª—é—á–∞—è –¥–Ω–∏ OOS –∏ –ø–æ—Å—Ç–∞–≤–æ–∫
        """
        logger.info("–†–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–π –¥–Ω–µ–≤–Ω–æ–π –ø—Ä–æ–¥–∞–∂–∏ (–∏—Å–∫–ª—é—á–∞—è –¥–Ω–∏ OOS –∏ –ø–æ—Å—Ç–∞–≤–æ–∫)...")
        
        if sales_df.empty:
            return pd.DataFrame()
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è OOS
        if stocks_df is not None and not stocks_df.empty:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–æ–¥–∞–∂–∏ —Å –æ—Å—Ç–∞—Ç–∫–∞–º–∏ –ø–æ SKU
            sales_with_stocks = sales_df.merge(stocks_df[['sku', 'available_stock']], on='sku', how='left')
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–Ω–∏ OOS: –∫–æ–≥–¥–∞ –æ—Å—Ç–∞—Ç–æ–∫ = 0 –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
            sales_with_stocks['is_oos'] = (sales_with_stocks['available_stock'].isna() | 
                                         (sales_with_stocks['available_stock'] == 0))
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–Ω–∏ –∫–æ–≥–¥–∞ —Ç–æ–≤–∞—Ä –±—ã–ª –≤ –Ω–∞–ª–∏—á–∏–∏ (–∏—Å–∫–ª—é—á–∞–µ–º –¥–Ω–∏ OOS)
            # –í–∫–ª—é—á–∞–µ–º –≤—Å–µ –¥–Ω–∏ —Å –Ω–∞–ª–∏—á–∏–µ–º —Ç–æ–≤–∞—Ä–∞, –¥–∞–∂–µ –µ—Å–ª–∏ –ø—Ä–æ–¥–∞–∂ –Ω–µ –±—ã–ª–æ
            days_with_stock = sales_with_stocks[~sales_with_stocks['is_oos']].copy()
            
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è OOS –¥–Ω–µ–π")
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É
            days_with_stock = sales_df.copy()
            logger.info(f"–î–∞–Ω–Ω—ã–µ –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–Ω–∏")
        
        if days_with_stock.empty:
            logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –¥–Ω—è—Ö —Å –Ω–∞–ª–∏—á–∏–µ–º —Ç–æ–≤–∞—Ä–∞")
            return pd.DataFrame()
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–Ω–∏ –ø–æ—Å—Ç–∞–≤–æ–∫ (–∫–æ–≥–¥–∞ –ø—Ä–æ–¥–∞–∂–∏ = 0 –∏ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ—Å—Ç–∞–≤–∫–∞)
        # –î–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –æ—Å—Ç–∞—Ç–∫–æ–≤, –Ω–æ –ø–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –ª–æ–≥–∏–∫—É
        # –î–Ω–∏ —Å –Ω—É–ª–µ–≤—ã–º–∏ –ø—Ä–æ–¥–∞–∂–∞–º–∏, –Ω–æ —Å –Ω–∞–ª–∏—á–∏–µ–º —Ç–æ–≤–∞—Ä–∞ - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ –¥–Ω–∏ –±–µ–∑ –ø—Ä–æ–¥–∞–∂
        # –î–Ω–∏ –ø–æ—Å—Ç–∞–≤–æ–∫ –±—É–¥—É—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã –Ω–∞ —É—Ä–æ–≤–Ω–µ stock_tracker
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ SKU –∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω—é—é –¥–Ω–µ–≤–Ω—É—é –ø—Ä–æ–¥–∞–∂—É –∑–∞ –¥–Ω–∏ —Å –Ω–∞–ª–∏—á–∏–µ–º —Ç–æ–≤–∞—Ä–∞
        daily_sales = days_with_stock.groupby('sku').agg({
            'quantity': 'sum',
            'date': 'nunique'
        }).reset_index()
        
        daily_sales['avg_daily_sales'] = daily_sales['quantity'] / daily_sales['date']
        daily_sales['total_sales_days'] = daily_sales['date']
        
        # –£–±–∏—Ä–∞–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–∞—Ç
        daily_sales = daily_sales.drop('date', axis=1)
        
        logger.info(f"–†–∞—Å—Å—á–∏—Ç–∞–Ω–∞ —Å—Ä–µ–¥–Ω—è—è –¥–Ω–µ–≤–Ω–∞—è –ø—Ä–æ–¥–∞–∂–∞ –¥–ª—è {len(daily_sales)} SKU (–∑–∞ –¥–Ω–∏ —Å –Ω–∞–ª–∏—á–∏–µ–º —Ç–æ–≤–∞—Ä–∞)")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        for _, row in daily_sales.head(3).iterrows():
            logger.info(f"SKU {row['sku']}: {row['avg_daily_sales']:.2f} —à—Ç/–¥–µ–Ω—å –∑–∞ {row['total_sales_days']} –¥–Ω–µ–π —Å –Ω–∞–ª–∏—á–∏–µ–º —Ç–æ–≤–∞—Ä–∞")
        
        return daily_sales
    
    def identify_oos_days(self, sales_df: pd.DataFrame, stocks_df: pd.DataFrame) -> pd.DataFrame:
        """
        –ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –¥–Ω–∏, –∫–æ–≥–¥–∞ —Ç–æ–≤–∞—Ä—ã –±—ã–ª–∏ –≤ OOS (out of stock) –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ü–µ–ª–µ–π
        """
        logger.info("–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–Ω–µ–π OOS –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...")
        
        if sales_df.empty or stocks_df.empty:
            return pd.DataFrame()
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ SKU
        date_range = pd.date_range(
            start=sales_df['date'].min(),
            end=sales_df['date'].max(),
            freq='D'
        )
        
        # –°–æ–∑–¥–∞–µ–º –≤—Å–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ SKU –∏ –¥–∞—Ç
        all_combinations = []
        for sku in sales_df['sku'].unique():
            for date in date_range:
                all_combinations.append({'sku': sku, 'date': date})
        
        combinations_df = pd.DataFrame(all_combinations)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –ø—Ä–æ–¥–∞–∂–∞–º–∏
        merged_df = combinations_df.merge(
            sales_df, on=['sku', 'date'], how='left'
        ).fillna(0)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–Ω–∏ OOS (–∫–æ–≥–¥–∞ –ø—Ä–æ–¥–∞–∂–∏ = 0)
        merged_df['is_oos'] = merged_df['quantity'] == 0
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É OOS –¥–ª—è –∫–∞–∂–¥–æ–≥–æ SKU
        oos_stats = merged_df.groupby('sku').agg({
            'is_oos': 'sum',
            'date': 'count'
        }).reset_index()
        
        oos_stats['oos_percentage'] = (oos_stats['is_oos'] / oos_stats['date'] * 100).round(1)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É OOS
        for _, row in oos_stats.head(5).iterrows():
            logger.info(f"SKU {row['sku']}: {row['oos_percentage']}% –¥–Ω–µ–π OOS ({row['is_oos']} –∏–∑ {row['date']} –¥–Ω–µ–π)")
        
        logger.info(f"–ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ {merged_df['is_oos'].sum()} –¥–Ω–µ–π OOS –∏–∑ {len(merged_df)} –æ–±—â–∏—Ö –¥–Ω–µ–π")
        return merged_df
    
    def calculate_forecast(self, sales_df: pd.DataFrame, stocks_df: pd.DataFrame) -> pd.DataFrame:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑ –∑–∞–∫—É–ø–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ SKU —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
        """
        logger.info("–†–∞—Å—á–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞ –∑–∞–∫—É–ø–æ–∫...")
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        if stocks_df.empty:
            logger.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞")
            return pd.DataFrame()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö
        total_stocks = stocks_df['available_stock'].sum()
        if total_stocks == 0:
            logger.warning("–í—Å–µ —Ç–æ–≤–∞—Ä—ã –∏–º–µ—é—Ç –Ω—É–ª–µ–≤—ã–µ –æ—Å—Ç–∞—Ç–∫–∏")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ SKU
        if not sales_df.empty:
            sales_skus = set(sales_df['sku'].unique())
            stocks_skus = set(stocks_df['sku'].unique())
            common_skus = sales_skus.intersection(stocks_skus)
            
            logger.info(f"SKU —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö: {len(sales_skus)}")
            logger.info(f"SKU —Å –¥–∞–Ω–Ω—ã–º–∏ –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö: {len(stocks_skus)}")
            logger.info(f"SKU —Å –ø–æ–ª–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏: {len(common_skus)}")
            
            if len(common_skus) == 0:
                logger.warning("–ù–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É SKU –≤ –ø—Ä–æ–¥–∞–∂–∞—Ö –∏ –æ—Å—Ç–∞—Ç–∫–∞—Ö")
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ä–µ–¥–Ω–µ–π –ø—Ä–æ–¥–∞–∂–∏
        if not sales_df.empty:
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω—é—é –¥–Ω–µ–≤–Ω—É—é –ø—Ä–æ–¥–∞–∂—É –∏–∑ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö
            daily_sales = self.calculate_daily_sales(sales_df, stocks_df)
            
            if not daily_sales.empty:
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –æ—Å—Ç–∞—Ç–∫–∞–º–∏
                forecast_df = daily_sales.merge(stocks_df, on='sku', how='left')
                logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ä–µ–¥–Ω–µ–π –ø—Ä–æ–¥–∞–∂–∏")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–∞
                forecast_df['forecast_quality'] = 'GOOD'
                
                # SKU —Å –º–∞–ª—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–Ω–µ–π –ø—Ä–æ–¥–∞–∂
                low_data_skus = forecast_df[forecast_df['total_sales_days'] < DAYS_TO_ANALYZE]
                if not low_data_skus.empty:
                    forecast_df.loc[low_data_skus.index, 'forecast_quality'] = 'LOW_DATA'
                    logger.warning(f"{len(low_data_skus)} SKU –∏–º–µ—é—Ç –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö (< {DAYS_TO_ANALYZE} –¥–Ω–µ–π)")
                
                # SKU —Å –Ω—É–ª–µ–≤–æ–π —Å—Ä–µ–¥–Ω–µ–π –ø—Ä–æ–¥–∞–∂–µ–π
                zero_sales_skus = forecast_df[forecast_df['avg_daily_sales'] == 0]
                if not zero_sales_skus.empty:
                    forecast_df.loc[zero_sales_skus.index, 'forecast_quality'] = 'NO_SALES'
                    logger.warning(f"{len(zero_sales_skus)} SKU –∏–º–µ—é—Ç –Ω—É–ª–µ–≤—É—é —Å—Ä–µ–¥–Ω—é—é –ø—Ä–æ–¥–∞–∂—É")
                
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –ª–æ–≥–∏–∫—É
                forecast_df = stocks_df.copy()
                forecast_df['avg_daily_sales'] = 1.0  # 1 —à—Ç –≤ –¥–µ–Ω—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                forecast_df['total_sales_days'] = 0
                forecast_df['forecast_quality'] = 'NO_SALES_DATA'
                logger.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –ø—Ä–æ–¥–∞–∂—É 1 —à—Ç/–¥–µ–Ω—å")
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –ª–æ–≥–∏–∫—É
            forecast_df = stocks_df.copy()
            forecast_df['avg_daily_sales'] = 1.0  # 1 —à—Ç –≤ –¥–µ–Ω—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            forecast_df['total_sales_days'] = 0
            forecast_df['forecast_quality'] = 'NO_SALES_DATA'
            logger.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –ø—Ä–æ–¥–∞–∂—É 1 —à—Ç/–¥–µ–Ω—å")
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º, –Ω–∞ —Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π —Ö–≤–∞—Ç–∏—Ç —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø–∞—Å–∞
        forecast_df['days_until_stockout'] = np.where(
            forecast_df['avg_daily_sales'] > 0,
            forecast_df['available_stock'] / forecast_df['avg_daily_sales'],
            float('inf')
        )
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –∑–∞–∫—É–ø–∫–∏
        forecast_df['needs_purchase_short'] = forecast_df['days_until_stockout'] < self.days_forecast_short
        forecast_df['needs_purchase_long'] = forecast_df['days_until_stockout'] < self.days_forecast_long
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è –∑–∞–∫—É–ø–∫–∏
        forecast_df['recommended_quantity'] = np.where(
            forecast_df['needs_purchase_short'],
            np.maximum(
                (self.days_forecast_long - forecast_df['days_until_stockout']) * forecast_df['avg_daily_sales'],
                forecast_df['avg_daily_sales'] * self.days_forecast_short
            ),
            0
        )
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä—Ç–∏–∏
        forecast_df['moq'] = forecast_df['sku'].apply(get_moq_for_sku)
        forecast_df['final_order_quantity'] = np.where(
            forecast_df['recommended_quantity'] > 0,
            np.maximum(forecast_df['recommended_quantity'], forecast_df['moq']),
            0
        )
        
        # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª
        forecast_df['final_order_quantity'] = forecast_df['final_order_quantity'].round().astype(int)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞
        quality_stats = forecast_df['forecast_quality'].value_counts()
        logger.info("–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ –ø–æ SKU:")
        for quality, count in quality_stats.items():
            logger.info(f"  {quality}: {count} SKU")
        
        logger.info(f"–†–∞—Å—Å—á–∏—Ç–∞–Ω –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è {len(forecast_df)} SKU")
        return forecast_df
    
    def generate_purchase_report(self, forecast_df: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ –∑–∞–∫—É–ø–∫–∞—Ö —Å —É—á–µ—Ç–æ–º –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞
        """
        logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –∑–∞–∫—É–ø–∫–∞—Ö...")
        
        if forecast_df.empty:
            return []
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º SKU, –∫–æ—Ç–æ—Ä—ã–µ —Ç—Ä–µ–±—É—é—Ç –∑–∞–∫—É–ø–∫–∏
        purchase_items = forecast_df[forecast_df['needs_purchase_short']].copy()
        
        if purchase_items.empty:
            logger.info("–ù–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤, —Ç—Ä–µ–±—É—é—â–∏—Ö –∑–∞–∫—É–ø–∫–∏")
            return []
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É (–ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ä–æ—á–Ω–æ—Å—Ç–∏)
        purchase_items = purchase_items.sort_values('days_until_stockout', ascending=True)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        report = []
        for _, row in purchase_items.iterrows():
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–æ–≥–Ω–æ–∑–µ
            confidence = self._get_forecast_confidence(row['forecast_quality'], row['total_sales_days'])
            
            report_item = {
                'sku': row['sku'],
                'avg_daily_sales': round(row['avg_daily_sales'], 2),
                'current_stock': int(row['available_stock']),
                'days_until_stockout': round(row['days_until_stockout'], 1),
                'recommended_quantity': int(row['final_order_quantity']),
                'moq': int(row['moq']),
                'forecast_quality': row['forecast_quality'],
                'confidence': confidence,
                'urgency': 'HIGH' if row['days_until_stockout'] < 10 else 'MEDIUM' if row['days_until_stockout'] < 20 else 'LOW'
            }
            report.append(report_item)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –ø—Ä–æ–≥–Ω–æ–∑–∞
        quality_stats = purchase_items['forecast_quality'].value_counts()
        logger.info("–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤, —Ç—Ä–µ–±—É—é—â–∏—Ö –∑–∞–∫—É–ø–∫–∏:")
        for quality, count in quality_stats.items():
            logger.info(f"  {quality}: {count} SKU")
        
        logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –æ—Ç—á–µ—Ç –¥–ª—è {len(report)} SKU")
        return report
    
    def _get_forecast_confidence(self, quality: str, sales_days: int) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–æ–≥–Ω–æ–∑–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
        """
        if quality == 'GOOD':
            if sales_days >= 30:
                return 'HIGH'
            elif sales_days >= 14:
                return 'MEDIUM'
            else:
                return 'LOW'
        elif quality == 'LOW_DATA':
            return 'LOW'
        elif quality == 'NO_SALES':
            return 'VERY_LOW'
        elif quality == 'NO_SALES_DATA':
            return 'VERY_LOW'
        else:
            return 'UNKNOWN'
    
    def generate_telegram_message(self, report: List[Dict[str, Any]]) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è Telegram —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–æ–≥–Ω–æ–∑–∞
        """
        if not report:
            return "–ù–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤, —Ç—Ä–µ–±—É—é—â–∏—Ö –∑–∞–∫—É–ø–∫–∏."
        
        message = "üõí *–û—Ç—á–µ—Ç –æ –∑–∞–∫—É–ø–∫–∞—Ö*\n\n"
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —É—Ä–æ–≤–Ω—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        high_confidence = [item for item in report if item['confidence'] == 'HIGH']
        medium_confidence = [item for item in report if item['confidence'] == 'MEDIUM']
        low_confidence = [item for item in report if item['confidence'] in ['LOW', 'VERY_LOW']]
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–≤–∞—Ä—ã —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        if high_confidence:
            message += "üü¢ *–í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:*\n"
            for item in high_confidence[:5]:
                sku = item['sku']
                days_left = item['days_until_stockout']
                quantity = item['recommended_quantity']
                urgency_emoji = "üî¥" if item['urgency'] == 'HIGH' else "üü°" if item['urgency'] == 'MEDIUM' else "üü¢"
                message += f"{urgency_emoji} {sku} ‚Üí {days_left} –¥–Ω–µ–π. –ó–∞–∫–∞–∑–∞—Ç—å {quantity} —à—Ç\n"
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–≤–∞—Ä—ã —Å–æ —Å—Ä–µ–¥–Ω–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        if medium_confidence:
            message += "\nüü° *–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:*\n"
            for item in medium_confidence[:3]:
                sku = item['sku']
                days_left = item['days_until_stockout']
                quantity = item['recommended_quantity']
                urgency_emoji = "üî¥" if item['urgency'] == 'HIGH' else "üü°" if item['urgency'] == 'MEDIUM' else "üü¢"
                message += f"{urgency_emoji} {sku} ‚Üí {days_left} –¥–Ω–µ–π. –ó–∞–∫–∞–∑–∞—Ç—å {quantity} —à—Ç\n"
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–≤–∞—Ä—ã —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        if low_confidence:
            message += "\nüî¥ *–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (—Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏):*\n"
            for item in low_confidence[:3]:
                sku = item['sku']
                days_left = item['days_until_stockout']
                quantity = item['recommended_quantity']
                quality = item['forecast_quality']
                urgency_emoji = "üî¥" if item['urgency'] == 'HIGH' else "üü°" if item['urgency'] == 'MEDIUM' else "üü¢"
                message += f"{urgency_emoji} {sku} ‚Üí {days_left} –¥–Ω–µ–π. –ó–∞–∫–∞–∑–∞—Ç—å {quantity} —à—Ç ({quality})\n"
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_items = len(report)
        high_count = len(high_confidence)
        medium_count = len(medium_confidence)
        low_count = len(low_confidence)
        
        message += f"\nüìä *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:*\n"
        message += f"–í—Å–µ–≥–æ –ø–æ–∑–∏—Ü–∏–π: {total_items}\n"
        message += f"–í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {high_count}\n"
        message += f"–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {medium_count}\n"
        message += f"–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {low_count}\n"
        
        if len(report) > 10:
            message += f"\n... –∏ –µ—â–µ {len(report) - 10} –ø–æ–∑–∏—Ü–∏–π"
        
        return message
    
    def analyze_seasonality(self, sales_df: pd.DataFrame) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        logger.info("–ê–Ω–∞–ª–∏–∑ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–æ–¥–∞–∂...")
        
        if sales_df.empty:
            return {}
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏ –∏ –º–µ—Å—è—Ü
        sales_df['day_of_week'] = sales_df['date'].dt.dayofweek
        sales_df['month'] = sales_df['date'].dt.month
        sales_df['week'] = sales_df['date'].dt.isocalendar().week
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
        daily_pattern = sales_df.groupby('day_of_week')['quantity'].agg(['mean', 'std', 'count']).reset_index()
        daily_pattern['day_name'] = ['–ü–Ω', '–í—Ç', '–°—Ä', '–ß—Ç', '–ü—Ç', '–°–±', '–í—Å']
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ –º–µ—Å—è—Ü–∞–º
        monthly_pattern = sales_df.groupby('month')['quantity'].agg(['mean', 'std', 'count']).reset_index()
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏–π –º–µ—Å—è—Ü–µ–≤
        month_names = {
            1: '–Ø–Ω–≤', 2: '–§–µ–≤', 3: '–ú–∞—Ä', 4: '–ê–ø—Ä', 5: '–ú–∞–π', 6: '–ò—é–Ω',
            7: '–ò—é–ª', 8: '–ê–≤–≥', 9: '–°–µ–Ω', 10: '–û–∫—Ç', 11: '–ù–æ—è', 12: '–î–µ–∫'
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—è—Ü–µ–≤ —Ç–æ–ª—å–∫–æ –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–µ—Å—è—Ü–µ–≤
        monthly_pattern['month_name'] = monthly_pattern['month'].map(month_names)
        
        # –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫–æ–≤—ã–µ –¥–Ω–∏ –∏ –º–µ—Å—è—Ü—ã
        peak_day = daily_pattern.loc[daily_pattern['mean'].idxmax()]
        peak_month = monthly_pattern.loc[monthly_pattern['mean'].idxmax()]
        
        seasonality_data = {
            'daily_pattern': daily_pattern.to_dict('records'),
            'monthly_pattern': monthly_pattern.to_dict('records'),
            'peak_day': {
                'day': peak_day['day_name'],
                'avg_sales': round(peak_day['mean'], 2)
            },
            'peak_month': {
                'month': peak_month['month_name'],
                'avg_sales': round(peak_month['mean'], 2)
            }
        }
        
        logger.info(f"–ü–∏–∫–æ–≤—ã–π –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏: {peak_day['day_name']} ({peak_day['mean']:.2f} —à—Ç)")
        logger.info(f"–ü–∏–∫–æ–≤—ã–π –º–µ—Å—è—Ü: {peak_month['month_name']} ({peak_month['mean']:.2f} —à—Ç)")
        
        return seasonality_data
    
    def export_report_to_csv(self, report: List[Dict[str, Any]], filename: str = None) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –≤ CSV —Ñ–∞–π–ª
        """
        if not report:
            logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return ""
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"purchase_forecast_{timestamp}.csv"
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        reports_dir = Path("reports")
        reports_dir.mkdir(exist_ok=True)
        
        filepath = reports_dir / filename
        
        try:
            with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = [
                    'sku', 'avg_daily_sales', 'current_stock', 'days_until_stockout',
                    'recommended_quantity', 'moq', 'forecast_quality', 'confidence', 'urgency'
                ]
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(report)
            
            logger.info(f"–û—Ç—á–µ—Ç —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ {filepath}")
            return str(filepath)
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –æ—Ç—á–µ—Ç–∞: {e}")
            return ""
    
    def export_report_to_json(self, report: List[Dict[str, Any]], filename: str = None) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –≤ JSON —Ñ–∞–π–ª —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        if not report:
            logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return ""
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"purchase_forecast_{timestamp}.json"
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        reports_dir = Path("reports")
        reports_dir.mkdir(exist_ok=True)
        
        filepath = reports_dir / filename
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        export_data = {
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'total_items': len(report),
                'forecast_period_short': self.days_forecast_short,
                'forecast_period_long': self.days_forecast_long,
                'version': '1.0'
            },
            'summary': {
                'high_confidence': len([item for item in report if item['confidence'] == 'HIGH']),
                'medium_confidence': len([item for item in report if item['confidence'] == 'MEDIUM']),
                'low_confidence': len([item for item in report if item['confidence'] in ['LOW', 'VERY_LOW']]),
                'high_urgency': len([item for item in report if item['urgency'] == 'HIGH']),
                'medium_urgency': len([item for item in report if item['urgency'] == 'MEDIUM']),
                'low_urgency': len([item for item in report if item['urgency'] == 'LOW'])
            },
            'items': report
        }
        
        try:
            with open(filepath, 'w', encoding='utf-8') as jsonfile:
                json.dump(export_data, jsonfile, ensure_ascii=False, indent=2)
            
            logger.info(f"–û—Ç—á–µ—Ç —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ {filepath}")
            return str(filepath)
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –æ—Ç—á–µ—Ç–∞: {e}")
            return ""
    
    def get_forecast_analytics(self, forecast_df: pd.DataFrame) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞–Ω–∞–ª–∏—Ç–∏–∫—É –ø–æ –ø—Ä–æ–≥–Ω–æ–∑—É
        """
        if forecast_df.empty:
            return {}
        
        analytics = {
            'total_skus': len(forecast_df),
            'skus_needing_purchase': len(forecast_df[forecast_df['needs_purchase_short']]),
            'skus_critical': len(forecast_df[forecast_df['days_until_stockout'] < DAYS_TO_ANALYZE]),
            'skus_urgent': len(forecast_df[forecast_df['days_until_stockout'] < 14]),
            'total_recommended_quantity': int(forecast_df['final_order_quantity'].sum()),
            'avg_days_until_stockout': round(forecast_df['days_until_stockout'].mean(), 1),
            'quality_distribution': forecast_df['forecast_quality'].value_counts().to_dict(),
            'stock_levels': {
                'low_stock': len(forecast_df[forecast_df['available_stock'] < 10]),
                'medium_stock': len(forecast_df[(forecast_df['available_stock'] >= 10) & (forecast_df['available_stock'] < 50)]),
                'high_stock': len(forecast_df[forecast_df['available_stock'] >= 50])
            }
        }
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –ø—Ä–æ–≥–Ω–æ–∑–∞
        quality_analytics = {}
        for quality in forecast_df['forecast_quality'].unique():
            quality_df = forecast_df[forecast_df['forecast_quality'] == quality]
            quality_analytics[quality] = {
                'count': len(quality_df),
                'avg_days_until_stockout': round(quality_df['days_until_stockout'].mean(), 1),
                'total_recommended_quantity': int(quality_df['final_order_quantity'].sum())
            }
        
        analytics['quality_analytics'] = quality_analytics
        
        logger.info(f"–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞: {analytics['skus_needing_purchase']} SKU —Ç—Ä–µ–±—É—é—Ç –∑–∞–∫—É–ø–∫–∏")
        logger.info(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–∑–∏—Ü–∏–π: {analytics['skus_critical']}")
        logger.info(f"–û–±—â–µ–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {analytics['total_recommended_quantity']} —à—Ç")
        
        return analytics
    
    def validate_forecast_data(self, forecast_df: pd.DataFrame) -> Tuple[bool, List[str]]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∞
        """
        errors = []
        
        if forecast_df.empty:
            errors.append("–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞ –ø—É—Å—Ç")
            return False, errors
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        required_columns = [
            'sku', 'avg_daily_sales', 'available_stock', 'days_until_stockout',
            'needs_purchase_short', 'final_order_quantity'
        ]
        
        missing_columns = [col for col in required_columns if col not in forecast_df.columns]
        if missing_columns:
            errors.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
        if 'days_until_stockout' in forecast_df.columns:
            negative_days = forecast_df[forecast_df['days_until_stockout'] < 0]
            if not negative_days.empty:
                errors.append(f"–ù–∞–π–¥–µ–Ω–æ {len(negative_days)} SKU —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ –¥–Ω—è–º–∏ –¥–æ –∏—Å—á–µ—Ä–ø–∞–Ω–∏—è")
        
        if 'final_order_quantity' in forecast_df.columns:
            negative_quantity = forecast_df[forecast_df['final_order_quantity'] < 0]
            if not negative_quantity.empty:
                errors.append(f"–ù–∞–π–¥–µ–Ω–æ {len(negative_quantity)} SKU —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã–±—Ä–æ—Å—ã
        if 'avg_daily_sales' in forecast_df.columns:
            q3 = forecast_df['avg_daily_sales'].quantile(0.75)
            iqr = forecast_df['avg_daily_sales'].quantile(0.75) - forecast_df['avg_daily_sales'].quantile(0.25)
            upper_bound = q3 + 1.5 * iqr
            outliers = forecast_df[forecast_df['avg_daily_sales'] > upper_bound]
            if not outliers.empty:
                errors.append(f"–ù–∞–π–¥–µ–Ω–æ {len(outliers)} SKU —Å –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã—Å–æ–∫–æ–π —Å—Ä–µ–¥–Ω–µ–π –ø—Ä–æ–¥–∞–∂–µ–π")
        
        return len(errors) == 0, errors 
    
    def compare_with_historical_forecast(self, current_forecast: pd.DataFrame, 
                                       historical_data: pd.DataFrame) -> Dict[str, Any]:
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–≥–Ω–æ–∑ —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏
        """
        logger.info("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏...")
        
        if current_forecast.empty or historical_data.empty:
            return {}
        
        comparison = {
            'total_skus': len(current_forecast),
            'accuracy_metrics': {},
            'trends': {}
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –¥–∞–Ω–Ω—ã—Ö
        for quality in current_forecast['forecast_quality'].unique():
            quality_df = current_forecast[current_forecast['forecast_quality'] == quality]
            
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏
            # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            comparison['accuracy_metrics'][quality] = {
                'count': len(quality_df),
                'avg_days_until_stockout': round(quality_df['days_until_stockout'].mean(), 1),
                'avg_recommended_quantity': round(quality_df['final_order_quantity'].mean(), 1)
            }
        
        logger.info("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        return comparison
    
    def generate_dashboard_data(self, forecast_df: pd.DataFrame, 
                               sales_df: pd.DataFrame = None) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞
        """
        logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞...")
        
        dashboard_data = {
            'summary': {},
            'charts': {},
            'alerts': []
        }
        
        if not forecast_df.empty:
            # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            dashboard_data['summary'] = {
                'total_skus': len(forecast_df),
                'skus_needing_purchase': len(forecast_df[forecast_df['needs_purchase_short']]),
                'critical_skus': len(forecast_df[forecast_df['days_until_stockout'] < DAYS_TO_ANALYZE]),
                'total_recommended_quantity': int(forecast_df['final_order_quantity'].sum()),
                'avg_days_until_stockout': round(forecast_df['days_until_stockout'].mean(), 1)
            }
            
            # –î–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
            dashboard_data['charts'] = {
                'quality_distribution': forecast_df['forecast_quality'].value_counts().to_dict(),
                'urgency_distribution': {
                    'HIGH': len(forecast_df[forecast_df['days_until_stockout'] < 10]),
                    'MEDIUM': len(forecast_df[(forecast_df['days_until_stockout'] >= 10) & 
                                            (forecast_df['days_until_stockout'] < 20)]),
                    'LOW': len(forecast_df[forecast_df['days_until_stockout'] >= 20])
                },
                'stock_levels': {
                    'low': len(forecast_df[forecast_df['available_stock'] < 10]),
                    'medium': len(forecast_df[(forecast_df['available_stock'] >= 10) & 
                                            (forecast_df['available_stock'] < 50)]),
                    'high': len(forecast_df[forecast_df['available_stock'] >= 50])
                }
            }
            
            # –ê–ª–µ—Ä—Ç—ã
            critical_items = forecast_df[forecast_df['days_until_stockout'] < 3]
            if not critical_items.empty:
                dashboard_data['alerts'].append({
                    'type': 'CRITICAL',
                    'message': f"{len(critical_items)} —Ç–æ–≤–∞—Ä–æ–≤ —Å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∏–º –æ—Å—Ç–∞—Ç–∫–æ–º (< 3 –¥–Ω–µ–π)",
                    'count': len(critical_items)
                })
            
            low_confidence_items = forecast_df[forecast_df['forecast_quality'].isin(['LOW_DATA', 'NO_SALES'])]
            if not low_confidence_items.empty:
                dashboard_data['alerts'].append({
                    'type': 'WARNING',
                    'message': f"{len(low_confidence_items)} —Ç–æ–≤–∞—Ä–æ–≤ —Å –Ω–∏–∑–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º –ø—Ä–æ–≥–Ω–æ–∑–∞",
                    'count': len(low_confidence_items)
                })
        
        # –ê–Ω–∞–ª–∏–∑ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö
        if sales_df is not None and not sales_df.empty:
            seasonality = self.analyze_seasonality(sales_df)
            dashboard_data['seasonality'] = seasonality
        
        logger.info("–î–∞–Ω–Ω—ã–µ –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã")
        return dashboard_data
    
    def get_forecast_recommendations(self, forecast_df: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        recommendations = []
        
        if forecast_df.empty:
            return recommendations
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
        low_data_skus = forecast_df[forecast_df['forecast_quality'] == 'LOW_DATA']
        if not low_data_skus.empty:
            recommendations.append({
                'type': 'DATA_QUALITY',
                'priority': 'HIGH',
                'message': f"–£–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(low_data_skus)} SKU",
                'action': '–°–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö',
                'affected_skus': len(low_data_skus)
            })
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–∑–∏—Ü–∏–∏
        critical_skus = forecast_df[forecast_df['days_until_stockout'] < DAYS_TO_ANALYZE]
        if not critical_skus.empty:
            recommendations.append({
                'type': 'URGENT_PURCHASE',
                'priority': 'CRITICAL',
                'message': f"–°—Ä–æ—á–Ω–æ –∑–∞–∫—É–ø–∏—Ç—å {len(critical_skus)} –ø–æ–∑–∏—Ü–∏–π",
                'action': '–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –æ—Ñ–æ—Ä–º–∏—Ç—å –∑–∞–∫–∞–∑—ã',
                'affected_skus': len(critical_skus)
            })
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—ã–±—Ä–æ—Å—ã –≤ –ø—Ä–æ–¥–∞–∂–∞—Ö
        if 'avg_daily_sales' in forecast_df.columns:
            q3 = forecast_df['avg_daily_sales'].quantile(0.75)
            iqr = forecast_df['avg_daily_sales'].quantile(0.75) - forecast_df['avg_daily_sales'].quantile(0.25)
            upper_bound = q3 + 1.5 * iqr
            outliers = forecast_df[forecast_df['avg_daily_sales'] > upper_bound]
            
            if not outliers.empty:
                recommendations.append({
                    'type': 'SALES_OUTLIERS',
                    'priority': 'MEDIUM',
                    'message': f"–ü—Ä–æ–≤–µ—Ä–∏—Ç—å {len(outliers)} SKU —Å –∞–Ω–æ–º–∞–ª—å–Ω–æ –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–¥–∞–∂–µ–π",
                    'action': '–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö',
                    'affected_skus': len(outliers)
                })
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–≤–∞—Ä—ã —Å –Ω—É–ª–µ–≤–æ–π –ø—Ä–æ–¥–∞–∂–µ–π
        zero_sales = forecast_df[forecast_df['avg_daily_sales'] == 0]
        if not zero_sales.empty:
            recommendations.append({
                'type': 'ZERO_SALES',
                'priority': 'MEDIUM',
                'message': f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å {len(zero_sales)} SKU —Å –Ω—É–ª–µ–≤–æ–π –ø—Ä–æ–¥–∞–∂–µ–π",
                'action': '–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å —Ç–æ–≤–∞—Ä–æ–≤',
                'affected_skus': len(zero_sales)
            })
        
        logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(recommendations)} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
        return recommendations
    
    def create_forecast_summary_report(self, forecast_df: pd.DataFrame, 
                                     analytics: Dict[str, Any] = None,
                                     recommendations: List[Dict[str, Any]] = None) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç-—Ä–µ–∑—é–º–µ –ø–æ –ø—Ä–æ–≥–Ω–æ–∑—É
        """
        if forecast_df.empty:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞"
        
        report_lines = []
        report_lines.append("=" * 60)
        report_lines.append("–û–¢–ß–ï–¢ –ü–û –ü–†–û–ì–ù–û–ó–£ –ó–ê–ö–£–ü–û–ö")
        report_lines.append("=" * 60)
        report_lines.append(f"–î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("")
        
        # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_skus = len(forecast_df)
        skus_needing_purchase = len(forecast_df[forecast_df['needs_purchase_short']])
        critical_skus = len(forecast_df[forecast_df['days_until_stockout'] < DAYS_TO_ANALYZE])
        total_quantity = int(forecast_df['final_order_quantity'].sum())
        
        report_lines.append("–û–°–ù–û–í–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        report_lines.append(f"  ‚Ä¢ –í—Å–µ–≥–æ SKU: {total_skus}")
        report_lines.append(f"  ‚Ä¢ –¢—Ä–µ–±—É—é—Ç –∑–∞–∫—É–ø–∫–∏: {skus_needing_purchase}")
        report_lines.append(f"  ‚Ä¢ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–∑–∏—Ü–∏–π: {critical_skus}")
        report_lines.append(f"  ‚Ä¢ –û–±—â–µ–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {total_quantity} —à—Ç")
        report_lines.append("")
        
        # –ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–∞
        quality_stats = forecast_df['forecast_quality'].value_counts()
        report_lines.append("–ö–ê–ß–ï–°–¢–í–û –ü–†–û–ì–ù–û–ó–ê:")
        for quality, count in quality_stats.items():
            percentage = (count / total_skus) * 100
            report_lines.append(f"  ‚Ä¢ {quality}: {count} SKU ({percentage:.1f}%)")
        report_lines.append("")
        
        # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
        if analytics:
            report_lines.append("–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ê–ù–ê–õ–ò–¢–ò–ö–ê:")
            if 'stock_levels' in analytics:
                levels = analytics['stock_levels']
                report_lines.append(f"  ‚Ä¢ –ù–∏–∑–∫–∏–π –æ—Å—Ç–∞—Ç–æ–∫ (< 10): {levels.get('low', 0)} SKU")
                report_lines.append(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π –æ—Å—Ç–∞—Ç–æ–∫ (10-50): {levels.get('medium', 0)} SKU")
                report_lines.append(f"  ‚Ä¢ –í—ã—Å–æ–∫–∏–π –æ—Å—Ç–∞—Ç–æ–∫ (> 50): {levels.get('high', 0)} SKU")
            report_lines.append("")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        if recommendations:
            report_lines.append("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            for i, rec in enumerate(recommendations[:5], 1):
                priority_emoji = "üî¥" if rec['priority'] == 'CRITICAL' else "üü°" if rec['priority'] == 'HIGH' else "üü¢"
                report_lines.append(f"  {i}. {priority_emoji} {rec['message']}")
                report_lines.append(f"     –î–µ–π—Å—Ç–≤–∏–µ: {rec['action']}")
            report_lines.append("")
        
        report_lines.append("=" * 60)
        
        return "\n".join(report_lines)
    
    def calculate_ml_enhanced_forecast(self, sales_data: List[Dict[str, Any]], 
                                     stocks_data: List[Dict[str, Any]]) -> pd.DataFrame:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑ —Å —É–ª—É—á—à–µ–Ω–∏–µ–º –æ—Ç ML-–º–æ–¥–µ–ª–µ–π
        """
        logger.info("–†–∞—Å—á–µ—Ç ML-—É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞...")
        
        if not ML_AVAILABLE:
            logger.warning("ML –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–≥–Ω–æ–∑")
            return self.calculate_forecast(
                self.prepare_sales_data(sales_data),
                self.prepare_stocks_data(stocks_data)
            )
        
        try:
            # –°–æ–∑–¥–∞–µ–º ML –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é
            ml_integration = MLForecastIntegration()
            
            # –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–≥–Ω–æ–∑
            sales_df = self.prepare_sales_data(sales_data)
            stocks_df = self.prepare_stocks_data(stocks_data)
            base_forecast = self.calculate_forecast(sales_df, stocks_df)
            
            # –£–ª—É—á—à–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ —Å –ø–æ–º–æ—â—å—é ML
            enhanced_forecast = ml_integration.enhance_forecast_with_ml(
                base_forecast, sales_data
            )
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ML-–æ—Ç—á–µ—Ç
            ml_report = ml_integration.generate_ml_forecast_report(sales_data, stocks_data)
            
            if 'error' not in ml_report:
                logger.info("ML-–æ—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
                # –ú–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á–µ—Ç –≤ —Ñ–∞–π–ª –∏–ª–∏ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            
            logger.info(f"ML-—É–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω –¥–ª—è {len(enhanced_forecast)} SKU")
            return enhanced_forecast
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ ML-—É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return self.calculate_forecast(
                self.prepare_sales_data(sales_data),
                self.prepare_stocks_data(stocks_data)
            )
    
    def generate_ml_forecast_report(self, sales_data: List[Dict[str, Any]], 
                                  stocks_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç —Å ML-–ø—Ä–æ–≥–Ω–æ–∑–æ–º
        """
        if not ML_AVAILABLE:
            return {'error': 'ML –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞'}
        
        try:
            ml_integration = MLForecastIntegration()
            return ml_integration.generate_ml_forecast_report(sales_data, stocks_data)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ML-–æ—Ç—á–µ—Ç–∞: {e}")
            return {'error': str(e)} 